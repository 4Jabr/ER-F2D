# Multi-Modal Fusion of Event and RGB for Monocular Depth Estimation Using Transformer (ER-F2D)
<p>
<img src="img/model_architecture.png" width="900">
</p>
This repository is the Pytorch implementation of our work - Multi-Modal Fusion of Event and RGB for Monocular Depth Estimation Using Transformer.


## 
## Acknowledgement
This work was supported in part by Semiconductor Research Corporation (SRC), the Center for Brain-inspired Computing (C-BRIC), JUMP 2.0 PRISM, and the National Science Foundation (NSF) SOPHIA (CCF-1822923). I thank Dr.Jack Sampson and Dr.Mahmut Kandemir for their insightful discussions, and constructive suggestions which enhanced the quality of the paper.

